{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMjP5lZPZnsqhPl746RdagS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"WnFn8Gvk8prg"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!unzip -q /content/drive/MyDrive/face_age.zip"],"metadata":{"id":"vdqsF_B_8ysX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","import numpy as np\n","import os\n","import pandas as pd\n","import kagglehub\n","import tensorflow as tf\n","import cv2\n","import imghdr\n","from tensorflow.keras.metrics import Precision, Recall, Accuracy\n","from matplotlib import pyplot as plt\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Add\n","from tensorflow.keras.layers import Activation, GlobalAveragePooling2D, Dropout"],"metadata":{"id":"76MCgFHw86Rr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = 'face_age'"],"metadata":{"id":"nM6wkKyQ89y_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.random.set_seed(42)"],"metadata":{"id":"Dh5SMZDaQYUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["image_exts = [\"jpeg\",\"jpg\",\"bmp\",\"png\"]\n"],"metadata":{"id":"9dB39OPY9CqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/Alialmanea/age-gender-detection-using-opencv-with-python.git\n","%cd age-gender-detection-using-opencv-with-python"],"metadata":{"id":"bwHeDupFQ3n7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Creating Bias (segregating Male from female)**"],"metadata":{"id":"iGS7_s9gfy3K"}},{"cell_type":"code","source":["import cv2\n","import os\n","import shutil\n","\n","# Load gender classification model\n","gender_net = cv2.dnn.readNetFromCaffe(\"deploy_gender.prototxt\", \"gender_net.caffemodel\")\n","face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n","MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n","GENDER_LIST = ['Male', 'Female']\n","\n","# Source and target directories\n","# Updated source_dir to include the relative path\n","source_dir = \"../face_age\"\n","target_dir = \"face_age_male\"\n","\n","def detect_gender(img_path):\n","    img = cv2.imread(img_path)\n","    if img is None:\n","        return None\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n","\n","    for (x, y, w, h) in faces:\n","        face_img = img[y:y+h, x:x+w]\n","        blob = cv2.dnn.blobFromImage(face_img, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n","        gender_net.setInput(blob)\n","        gender_preds = gender_net.forward()\n","        return GENDER_LIST[gender_preds[0].argmax()]\n","    return None\n","\n","# Create filtered dataset\n","for age_folder in os.listdir(source_dir):\n","    age_path = os.path.join(source_dir, age_folder)\n","    if not os.path.isdir(age_path):\n","        continue\n","\n","    for img_name in os.listdir(age_path):\n","        img_path = os.path.join(age_path, img_name)\n","        gender = detect_gender(img_path)\n","\n","        if gender == \"Male\":\n","            target_age_path = os.path.join(target_dir, age_folder)\n","            os.makedirs(target_age_path, exist_ok=True)\n","            shutil.copy(img_path, os.path.join(target_age_path, img_name))"],"metadata":{"id":"_SLyZbBL9MNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","target_dir = \"face_age_male\"\n","\n","for age_class in os.listdir(target_dir):\n","    age_folder_path = os.path.join(target_dir, age_class)\n","    if not os.path.isdir(age_folder_path):\n","        continue\n","    print(f\"Age class: {age_class}\")\n","    images = os.listdir(age_folder_path)\n","    for img_name in images[:3]:\n","        print(\" \", os.path.join(age_folder_path, img_name))"],"metadata":{"id":"JZfy6IjZ9Mwb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import glob\n","for ds_store_file in glob.glob(f\"{data_dir}/**/.DS_Store\", recursive=True):\n","    os.remove(ds_store_file)"],"metadata":{"id":"MqA2Ad5cc4_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class_names = sorted(os.listdir(target_dir))\n","age_labels = [int(name) for name in class_names]  # Convert subdir names to integers\n","\n","# lookup table for class index → actual age\n","age_lookup = tf.constant(age_labels, dtype=tf.int32)\n","\n","# 3. Map dataset labels to actual ages\n","data = tf.keras.utils.image_dataset_from_directory(target_dir)\n","data = data.map(lambda x, y: (x, tf.gather(age_lookup, y)))\n","\n","# 4. Now apply your age-to-category mapping\n","def label_to_category(image, label):\n","    category = tf.where(\n","        label < 13, 0,\n","        tf.where(\n","            label < 20, 1,\n","            tf.where(label < 60, 2, 3)\n","        )\n","    )\n","    return image, tf.cast(category, tf.int32)\n","\n","dataset = data.map(label_to_category)\n"],"metadata":{"id":"UfqYX8JXdcVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_dir = '/content/face_age'\n","class_names = sorted(os.listdir(data_dir))\n","age_labels = [int(name) for name in class_names]  # Convert subdir names to integers\n","\n","# lookup table for class index → actual age\n","age_lookup = tf.constant(age_labels, dtype=tf.int32)\n","\n","# 3. Map dataset labels to actual ages\n","data = tf.keras.utils.image_dataset_from_directory(data_dir)\n","data = data.map(lambda x, y: (x, tf.gather(age_lookup, y)))\n","\n","# 4. Now apply your age-to-category mapping\n","def label_to_category(image, label):\n","    category = tf.where(\n","        label < 13, 0,\n","        tf.where(\n","            label < 20, 1,\n","            tf.where(label < 60, 2, 3)\n","        )\n","    )\n","    return image, tf.cast(category, tf.int32)\n","\n","dataset_general = data.map(label_to_category)\n"],"metadata":{"id":"JoNXruQujaZl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for image, label in dataset.take(1):\n","    print(\"Image shape:\", image.shape)\n","    print(\"Label:\", label)"],"metadata":{"id":"FGzYzix0ditl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset = dataset.map(lambda x,y:(x/255,y))"],"metadata":{"id":"w0snhxXCd2EU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_general = dataset_general.map(lambda x,y:(x/255,y))"],"metadata":{"id":"PN6dw1TomHNE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaled_iterator_1 = dataset.as_numpy_iterator()"],"metadata":{"id":"-88GpqbZd6EZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_dataset = scaled_iterator_1.next()"],"metadata":{"id":"piopBLvwV7vM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaled_iterator_2 = dataset_general.as_numpy_iterator()"],"metadata":{"id":"dl7xUGJ2mOS9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fix , ax = plt.subplots(ncols = 4,figsize = (20,20))\n","for indx,img in enumerate(batch_dataset[0][:4]):\n","    ax[indx].imshow((img * 255).astype(\"uint8\"))\n","    ax[indx].title.set_text(f\"Label: {batch_dataset[1][indx]}\") # Changed batch to batch_dataset"],"metadata":{"id":"Mw7ZXhL-ViO6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["length = dataset.cardinality().numpy()\n","\n","train_size_d = int(length * 0.8)\n","val_size_d = int(length * 0.2)\n","\n","train_dataset = dataset.take(train_size_d)\n","val_dataset = dataset.skip(train_size_d).take(val_size_d)"],"metadata":{"id":"B_GuGsWRd9UL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset_general = dataset_general.take(train_size_d)\n","val_dataset_general = dataset_general.skip(train_size_d).take(val_size_d)\n","\n"],"metadata":{"id":"XSNCErM7mSXX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_size_d = int(length * 0.1)\n","test_dataset = dataset_general.skip(train_size_d + val_size_d).take(test_size_d)\n"],"metadata":{"id":"QPrDEWTUEbj3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **DeepLearing MODEL(CLassification)**"],"metadata":{"id":"x7zVDhBTfDSG"}},{"cell_type":"code","source":["def build_simple_cnn(\n","    input_shape=(256, 256, 3),\n","    hidden_layers=2,\n","    filters=[32, 16],\n","    kernel_size=(3, 3),\n","    activation='relu',\n","    include_pooling=True,\n","    fc_layers=[256],  # list for FC layers: e.g., [256, 128]\n","    output_classes=4,\n","    use_skip_connections=False\n","):\n","    inputs = Input(shape=input_shape)\n","    x = Conv2D(16, kernel_size, padding='same', activation=activation)(inputs)\n","    if include_pooling:\n","        x = MaxPooling2D()(x)\n","\n","    prev = x  # to store for skip connection\n","\n","    for i in range(hidden_layers * 2):\n","        filter_idx = i % len(filters)\n","        current_filter = filters[filter_idx]\n","\n","        conv = Conv2D(current_filter, kernel_size, padding='same', activation=activation)(x)\n","\n","        if include_pooling:\n","            conv = MaxPooling2D()(conv)\n","\n","        if use_skip_connections and conv.shape == prev.shape:\n","            x = Add()([conv, prev])  # skip connection\n","        else:\n","            x = conv\n","\n","        prev = x\n","\n","    # Flatten or GlobalAvgPool\n","    x = Flatten()(x)  # or use GlobalAveragePooling2D()\n","\n","    # Fully Connected Layers\n","    for fc_size in fc_layers:\n","        x = Dense(fc_size, activation=activation)(x)\n","\n","    outputs = Dense(output_classes, activation='softmax')(x)\n","\n","    model = Model(inputs=inputs, outputs=outputs)\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    return model\n","\n","\n","\n","model_1 = build_simple_cnn(activation='tanh')\n","\n","model_2 = build_simple_cnn(activation='tanh')"],"metadata":{"id":"tCMLYnZuekLv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Training the model with only one gender(MALE)**"],"metadata":{"id":"FNoXYC9A5eTB"}},{"cell_type":"code","source":["hist_1 = model_1.fit(train_dataset,epochs = 20,validation_data = val_dataset)"],"metadata":{"id":"7ssPAWnffTZm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Training the model with Both Genders**"],"metadata":{"id":"TdwAkhet5o_G"}},{"cell_type":"code","source":["hist_2 = model_2.fit(train_dataset_general,epochs = 20,validation_data = val_dataset_general)"],"metadata":{"id":"cD_kyke-DOzX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_classification_model(model, test_dataset):\n","    pre = Precision()\n","    re = Recall()\n","    acc = Accuracy()\n","\n","    for batch in test_dataset.as_numpy_iterator():\n","        x, y = batch\n","        yhat = model.predict(x, verbose=0)\n","\n","        # Get true and predicted class indices\n","        y_true = y.argmax(axis=1) if y.ndim > 1 else y\n","        y_pred = yhat.argmax(axis=1)\n","\n","        # Update metrics\n","        pre.update_state(y_true, y_pred)\n","        re.update_state(y_true, y_pred)\n","        acc.update_state(y_true, y_pred)\n","\n","    precision = pre.result().numpy()\n","    recall = re.result().numpy()\n","    accuracy = acc.result().numpy()\n","    f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)  # Avoid division by zero\n","\n","    print(f\"Precision: {precision:.4f}\")\n","    print(f\"Recall: {recall:.4f}\")\n","    print(f\"Accuracy: {accuracy:.4f}\")\n","    print(f\"F1-score: {f1_score:.4f}\")\n","\n","    return {\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"accuracy\": accuracy,\n","        \"f1_score\": f1_score\n","    }\n"],"metadata":{"id":"_8YCUw2pFlY6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model_1_test = evaluate_classification_model(model_1, test_dataset)"],"metadata":{"id":"LUYRqn1EDbyZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_2_test = evaluate_classification_model(model_2, test_dataset)"],"metadata":{"id":"XHnev1MjFbJq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","\n","# Save regression model\n","model_1.save('gender_model_male.keras')\n","\n","# Save classification model\n","model_2.save('gender_model_general.keras')\n"],"metadata":{"id":"O51Cb-X0FmhC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import shutil\n","\n","os.makedirs(\"part_3_models\", exist_ok=True)\n","shutil.move(\"gender_model_male.keras\", \"part_3_models/gender_model_male.keras\")\n","shutil.move(\"gender_model_general.keras\", \"part_3_models/gender_model_general.keras\")\n","shutil.make_archive(\"part_3_models\", 'zip', \"part_3_models\")\n"],"metadata":{"id":"TRd8Cvsy5JRt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from google.colab import files\n","files.download('/content/age-gender-detection-using-opencv-with-python/part_3_models.zip')\n"],"metadata":{"id":"BRfCDChe5X-5"},"execution_count":null,"outputs":[]}]}